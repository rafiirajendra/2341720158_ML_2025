{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55212838",
   "metadata": {},
   "source": [
    "# Praktikum 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62febb7",
   "metadata": {},
   "source": [
    "\n",
    "Lakukan percobaan penggunaan ANNOY, FAISS, dan HNSWLIB pada dataset sekunder berukuran besar (Micro Spotify) pada link berikut: https://www.kaggle.com/datasets/bwandowando/spotify-songs-with-attributes-and-lyrics/data . Download data dan load CSV filenya (pilih dataset yg pertama dari dua dataset). pilih hanya fitur numerik saja, dan lakukan normalisasi menggunakan StandardScaler. Lakukan pencarian track terdekat dan bandingkan hasilnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b532e82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files:\n",
      "Exact NN done in 375.246 s\n",
      "Exact NN done in 375.246 s\n",
      "Annoy done in 36.000 s\n",
      "Annoy done in 36.000 s\n",
      "HNSW done in 26.064 s\n",
      "HNSW done in 26.064 s\n",
      "FAISS IVF done in 61.168 s\n",
      "\n",
      "Top-5 neighbors for first song:\n",
      "Exact NN: [     0 394553 764272 837727 749223]\n",
      "Annoy:    [0, 394553, 764272, 837727, 61511]\n",
      "HNSW:     [     0 394553 764272 837727 749223]\n",
      "FAISS:    [     0 394553 764272 837727 749223]\n",
      "FAISS IVF done in 61.168 s\n",
      "\n",
      "Top-5 neighbors for first song:\n",
      "Exact NN: [     0 394553 764272 837727 749223]\n",
      "Annoy:    [0, 394553, 764272, 837727, 61511]\n",
      "HNSW:     [     0 394553 764272 837727 749223]\n",
      "FAISS:    [     0 394553 764272 837727 749223]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import faiss\n",
    "from annoy import AnnoyIndex\n",
    "import hnswlib\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import kagglehub\n",
    "\n",
    "# -------------------------------\n",
    "# Load dataset\n",
    "# -------------------------------\n",
    "\n",
    "print(\"Path to dataset files:\")\n",
    "df = pd.read_csv(\"..\\data\\songs_with_attributes_and_lyrics.csv\")\n",
    "features = ['danceability', 'energy', 'loudness', 'speechiness', \n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "X = df[features].values\n",
    "\n",
    "# Standarisasi fitur\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "k = 10  # jumlah nearest neighbors\n",
    "\n",
    "# -------------------------------\n",
    "# Exact Nearest Neighbor (brute-force)\n",
    "# -------------------------------\n",
    "start = time.time()\n",
    "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
    "nn.fit(X_scaled)\n",
    "dist_exact, idx_exact = nn.kneighbors(X_scaled)\n",
    "time_exact = time.time() - start\n",
    "print(f\"Exact NN done in {time_exact:.3f} s\")\n",
    "\n",
    "# -------------------------------\n",
    "# Annoy\n",
    "# -------------------------------\n",
    "start = time.time()\n",
    "f = X_scaled.shape[1]\n",
    "index_annoy = AnnoyIndex(f, 'euclidean')\n",
    "for i, v in enumerate(X_scaled):\n",
    "    index_annoy.add_item(i, v)\n",
    "index_annoy.build(10)\n",
    "idx_annoy = [index_annoy.get_nns_by_vector(v, k) for v in X_scaled]\n",
    "time_annoy = time.time() - start\n",
    "print(f\"Annoy done in {time_annoy:.3f} s\")\n",
    "\n",
    "# -------------------------------\n",
    "# HNSW\n",
    "# -------------------------------\n",
    "start = time.time()\n",
    "p_hnsw = hnswlib.Index(space='l2', dim=X_scaled.shape[1])\n",
    "p_hnsw.init_index(max_elements=X_scaled.shape[0], ef_construction=200, M=16)\n",
    "p_hnsw.add_items(X_scaled)\n",
    "p_hnsw.set_ef(200)\n",
    "idx_hnsw, dist_hnsw = p_hnsw.knn_query(X_scaled, k=k)\n",
    "time_hnsw = time.time() - start\n",
    "print(f\"HNSW done in {time_hnsw:.3f} s\")\n",
    "\n",
    "# -------------------------------\n",
    "# FAISS IVF\n",
    "# -------------------------------\n",
    "start = time.time()\n",
    "quantizer = faiss.IndexFlatL2(X_scaled.shape[1])\n",
    "index_faiss = faiss.IndexIVFFlat(quantizer, X_scaled.shape[1], 100, faiss.METRIC_L2)\n",
    "index_faiss.train(X_scaled)\n",
    "index_faiss.add(X_scaled)\n",
    "index_faiss.nprobe = 10\n",
    "dist_faiss, idx_faiss = index_faiss.search(X_scaled, k)\n",
    "time_faiss = time.time() - start\n",
    "print(f\"FAISS IVF done in {time_faiss:.3f} s\")\n",
    "\n",
    "# -------------------------------\n",
    "# Contoh tampilkan top-5 neighbors dari item pertama\n",
    "# -------------------------------\n",
    "print(\"\\nTop-5 neighbors for first song:\")\n",
    "print(f\"Exact NN: {idx_exact[0][:5]}\")\n",
    "print(f\"Annoy:    {idx_annoy[0][:5]}\")\n",
    "print(f\"HNSW:     {idx_hnsw[0][:5]}\")\n",
    "print(f\"FAISS:    {idx_faiss[0][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b5c3d",
   "metadata": {},
   "source": [
    "Berikut analisa terhadap code pada Praktikum 6:\n",
    "\n",
    "### 1. Tujuan Percobaan\n",
    "Praktikum 6 bertujuan membandingkan performa tiga algoritma Approximate Nearest Neighbor (ANN): Annoy, FAISS, dan HNSWLIB pada dataset sekunder besar (Micro Spotify). Dataset diambil dari Kaggle dan hanya fitur numerik yang digunakan, lalu dinormalisasi dengan StandardScaler.\n",
    "\n",
    "### 2. Langkah-langkah Utama\n",
    "- **Load Dataset:** Membaca file CSV, memilih fitur numerik, dan melakukan normalisasi.\n",
    "- **Exact NN (Brute-force):** Menggunakan `NearestNeighbors` dari scikit-learn untuk mencari tetangga terdekat secara eksak.\n",
    "- **Annoy:** Membuat index Annoy dengan metrik Euclidean, membangun index, dan mencari tetangga terdekat.\n",
    "- **HNSWLIB:** Membuat index HNSW dengan metrik L2, membangun index, dan mencari tetangga terdekat.\n",
    "- **FAISS IVF:** Membuat index FAISS IVF, melakukan training, membangun index, dan mencari tetangga terdekat.\n",
    "- **Perbandingan Hasil:** Menampilkan waktu komputasi dan hasil tetangga terdekat dari item pertama untuk masing-masing algoritma.\n",
    "\n",
    "### 3. Analisa Kode\n",
    "- **Efisiensi:** \n",
    "  - Exact NN sangat akurat namun lambat untuk dataset besar.\n",
    "  - Annoy dan HNSWLIB jauh lebih cepat untuk pencarian, cocok untuk skenario real-time.\n",
    "  - FAISS IVF juga efisien, terutama untuk data besar dan mendukung optimasi lebih lanjut (GPU, nprobe).\n",
    "- **Akurasi:** \n",
    "  - ANN (Annoy, HNSWLIB, FAISS IVF) memberikan hasil tetangga yang sangat mirip dengan Exact NN, meski kadang ada perbedaan urutan.\n",
    "- **Scalability:** \n",
    "  - Semua algoritma ANN di sini mampu menangani ribuan hingga jutaan data, sedangkan Exact NN terbatas oleh memori dan waktu.\n",
    "- **Praktis:** \n",
    "  - Kode sudah modular dan mudah diadaptasi untuk dataset lain atau parameter berbeda.\n",
    "  - Penggunaan StandardScaler memastikan pencarian tetangga tidak bias akibat skala fitur.\n",
    "\n",
    "### 4. Kesimpulan\n",
    "Praktikum 6 menunjukkan bahwa Annoy, FAISS, dan HNSWLIB sangat efektif untuk pencarian tetangga terdekat pada dataset besar, dengan waktu komputasi jauh lebih cepat dibandingkan metode brute-force. Hasil tetangga yang ditemukan juga sangat mirip, sehingga ketiga algoritma ini layak digunakan untuk aplikasi rekomendasi seperti Spotify.\n",
    "\n",
    "Jika ingin analisa lebih mendalam (misal: visualisasi recall, perbandingan speedup, atau analisa overlap tetangga), dapat ditambahkan sesuai kebutuhan."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
